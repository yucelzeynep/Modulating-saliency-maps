# Graspable_objects
Four sets of images depicting objects different functional/manipulative characteristics

This repository contains four sets of images of graspable objects depicted over plain white background. Each set involves 8 gray scale images, collected from the Internet depicting objects with different sorts of functional/manipulative characteristics.

In describing functional/manipulative characteristics, we rely on definitions by Natraj et al. (2015). Namely, in interpreting tool affordances, the part where humans grasp and operate an object is typically
termed as its functional part. On the other hand, the end-effector, where the object realizes its purpose, is often termed as manipulative part. For instance, for a knife, the handle is the functional part and the blade is the manipulative part. 

As for object types, we consider the following four types. Specifically, we first distinguish two common forms of functional parts as bar-type and loop-type and build one set of images for each type. In addition, another set of images is dedicated to objects without any explicit functional part. Note that, although these object do not have a dedicated handle or grip, they may have with an intuitive location for grasping. The objects are usually containers such as jar, bottle, paper cup etc.  Moreover, a set of vegetable images is collected for representing non-tool graspable objects. 

Diffferent object types are collected under different folders {b, l, w, x}, where functional/manipulative characteristics are as follows.

| Folder | Object specifics |
| --- | --- |
| b | objects with *bar*-type grip  |
| l |  objects with *loop*-type grip  |
| w |  objects *without* any explicit grip   |
| x |   non-tools (i.e. vegetables)  |

It is demonstrated through a survey that viewers have quite similar ratings regarding their familiarity to the objects irrespective of their age or gender, and there is no peculiar object in the set.

**References**

Natraj, N., Pella, Y., Borghi, A., and Wheaton, L. (2015). The visual encoding of tool–object affordances.
Neuroscience 310, 512–527
